{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creation of your dataset",
      "provenance": [],
      "authorship_tag": "ABX9TyOCHHvvvCvHc6KOnYLXPK+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurCalvi/Classifieur-Bois/blob/master/Creation_of_your_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olMXdXPU-iaU"
      },
      "source": [
        "# WOOD CLASSIFIER - CREATE YOUR DATASET\n",
        "\n",
        "In this notebook, I provide a code to create a dataset with the help of the neural network. The net is used as a binary classifier to save images into the defect or clearwood folder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcMHEAnN_Lh_"
      },
      "source": [
        "**PART 0 : Google Drive Access**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEk-OMOZVc7Y",
        "outputId": "fd6e8bab-d92b-4d0a-a23c-d796cd660a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8hTmMLx-lIz"
      },
      "source": [
        "***First run:*** The GitHub folder containing the codes, models and image directories is copied to your google drive with the following path: Google Drive -> Project_google_colab -> Classification-Bois."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQnlhrL-gNI",
        "outputId": "7d89a1e4-d5bc-487d-d648-07d6f912490c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Project_google_colab\n",
        "! git clone https://github.com/ArthurCalvi/Classifieur-Bois"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Project_google_colab\n",
            "fatal: destination path 'Classifieur-Bois' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-GCETkI-ryv"
      },
      "source": [
        "***Other executions***: If you want to update the GitHub folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m7QpD1B-tHU",
        "outputId": "24aca293-2626-423f-ed2a-fd3f1b3b14c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Project_google_colab/Classifieur-Bois\n",
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Project_google_colab/Classifieur-Bois\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/ArthurCalvi/Classifieur-Bois\n",
            "   1e718f6..07ed2d0  master     -> origin/master\n",
            "Updating 1e718f6..07ed2d0\n",
            "Fast-forward\n",
            " Filter.ipynb | 399 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 1 file changed, 399 insertions(+)\n",
            " create mode 100644 Filter.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9-KrcYx_sMu"
      },
      "source": [
        "**PART 1 : Upload the images of your dataset**\n",
        "\n",
        "Please upload all the images in the IMAGES_raw folder on google drive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE6-nyFk_-vY"
      },
      "source": [
        "**PART 2: Creation of the Dataset**\n",
        "\n",
        "In this part all the images of the *IMAGES_raw* folders are first preprocessed and saved into the *IMAGES_preprocessed* folder, then the neural network is used to classify and save the images in the *New_Dataset/defect/* directory or *New_Dataset/clearwood/* directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-nDdFmMAltZ",
        "outputId": "29c07a06-db9f-4a12-f724-ba9d27b4c88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "##PARAMETERS\n",
        "#image width in px\n",
        "desired_size = 256\n",
        "\n",
        "#Nbr of augmented images used for prediction\n",
        "nbr_images = 10\n",
        "\n",
        "##IMPORTS\n",
        "#Import of the PIL image management library\n",
        "from PIL import Image \n",
        "\n",
        "#Import of os and sys libraries to manipulate files\n",
        "import sys,os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "#Imports of github personal files\n",
        "from custom_functions_v1 import crop_generator, random_crop, colorize_v2\n",
        "\n",
        "# Keras API\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "##FUNCTIONS\n",
        "def prep_image(image):\n",
        "    323/5000\n",
        "    \"\"\"This function takes as argument an image of any size and aspect opened\n",
        "    according to the PIL Image.open method and transforms it into a square\n",
        "    image of side 256 pixels. The cropping is performed such that the smallest\n",
        "    side is  fixed at 256 pixels and the largest side is then cropped to obtain\n",
        "    a square format.\"\"\"\n",
        "\n",
        "    #dimensions recovery\n",
        "    width,height = image.size\n",
        "\n",
        "    #smallest side recovery\n",
        "    small_side = min(width,height)\n",
        "\n",
        "    #definition of the ratio between the old and the new image\n",
        "    ratio = desired_size / small_side\n",
        "\n",
        "    #scaling\n",
        "    image = image.resize((round(ratio*width), round(ratio*height)), Image.ANTIALIAS )\n",
        "\n",
        "    #dimensions recovery\n",
        "    width,height = image.size\n",
        "\n",
        "    #definition of the region to crop\n",
        "    crop_region = ( round(( width-desired_size)/2), 0 , round((width+desired_size)/2) , desired_size)\n",
        "\n",
        "    #cropping \n",
        "    image = image.crop(crop_region)\n",
        "\n",
        "    return image\n",
        "\n",
        "def prep_and_save(path):\n",
        "    \"\"\"This function browses the images in the IMAGES_raw folder and saves it\n",
        "    in the IMAGES_preprocessed folder\"\"\"\n",
        "\n",
        "    dirs = os.listdir(path)\n",
        "    i=0\n",
        "\n",
        "    for item in dirs:\n",
        "        \n",
        "        super_path = path+\"/\"+item\n",
        "        \n",
        "        if os.path.isfile(super_path):\n",
        "            \n",
        "            image = Image.open(super_path)\n",
        "            \n",
        "            filename_w_ext = os.path.basename(super_path)\n",
        "            filename, extension = os.path.splitext(filename_w_ext)\n",
        "\n",
        "            image = prep_image(image)\n",
        "\n",
        "            image.save(save+\"/\"+filename+\"_{}.jpg\".format(desired_size), 'JPEG')\n",
        "            os.remove(super_path)\n",
        "\n",
        "            i+=1\n",
        "\n",
        "    print('{} images have been prepared and have been saved to Google Drive : My Drive/Project_google_colab/Classification-Bois/Images_preprocessed'.format(i))\n",
        "\n",
        "\n",
        "def prediction(img,nbr_images):\n",
        "    \"\"\" \n",
        "    Perform the prediction of the image [img] from [nbr_images] augmented\n",
        "    images.\n",
        "    \n",
        "    INPUT :\n",
        "        -img : array loaded with load_img \n",
        "        -nbr_images : integer representing the number of augmented images used\n",
        "         for prediction \n",
        "        \n",
        "        \n",
        "    OUTPUT :\n",
        "        -prediction : final prediction averaged over several images\n",
        "    \"\"\"\n",
        "    \n",
        "    # convert to numpy array\n",
        "    data = img_to_array(img)\n",
        "    # expand dimension to one sample\n",
        "    samples = np.expand_dims(data, 0)\n",
        "    \n",
        "    # create data for the test\n",
        "    datagen = ImageDataGenerator( fill_mode='reflect', \n",
        "                                  samplewise_center=True,\n",
        "                                  samplewise_std_normalization=True,\n",
        "                                  horizontal_flip=True, vertical_flip=True, \n",
        "                                  rotation_range=10, brightness_range= [0.6,1.4], \n",
        "                                  preprocessing_function = colorize_v2, \n",
        "                                  zoom_range = [1.0,1.3])\n",
        "    \n",
        "    batch = datagen.flow(samples, batch_size=1)\n",
        "    \n",
        "    #add random cropped\n",
        "    prediction = []\n",
        "    \n",
        "    for i in range(nbr_images):\n",
        "        \n",
        "        img = batch.next()\n",
        "        img = random_crop(img[0].astype('float32'), (224,224))\n",
        "        img = np.expand_dims(img, 0)\n",
        "        prediction.append(model.predict(img))\n",
        "    \n",
        "        \n",
        "    prediction = sum(prediction)/nbr_images\n",
        "    prediction = np.array(prediction).tolist()[0][0]\n",
        "    \n",
        "    return prediction  \n",
        "\n",
        "\n",
        "\n",
        "##SCRIPT\n",
        "\n",
        "#Directory to retrieve raw images\n",
        "access = '/content/drive/My Drive/Project_google_colab/Classifieur-Bois/IMAGES_raw'\n",
        "\n",
        "#Directory to save preprocessed images\n",
        "save = '/content/drive/My Drive/Project_google_colab/Classifieur-Bois/IMAGES_preprocessed'\n",
        "\n",
        "#Preparation of the images\n",
        "prep_and_save(access)\n",
        "\n",
        "#Loading model\n",
        "model = load_model('/content/drive/My Drive/Project_google_colab/Classifieur-Bois/MODEL_CNN1_bs32_ep100_augTrue_t1593511641.h5')\n",
        "\n",
        "#Use of the neural net to classify and save images\n",
        "dirs = os.listdir(save)\n",
        "\n",
        "i=0\n",
        "d=0\n",
        "c=0\n",
        "for item in dirs:\n",
        "    \n",
        "    if os.path.isfile(save+'/'+item):\n",
        "\n",
        "        img = load_img(save+'/'+item)\n",
        "        score = prediction(img, nbr_images)\n",
        "\n",
        "        if score>0.5:\n",
        "            img.save('/content/drive/My Drive/Project_google_colab/Classifieur-Bois/New_Dataset/defect/'+item)\n",
        "            i+=1\n",
        "            d+=1\n",
        "        else : \n",
        "            img.save('/content/drive/My Drive/Project_google_colab/Classifieur-Bois/New_Dataset/clearwood/'+item)\n",
        "            i+=1\n",
        "            c+=1\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "print(\"{} images have been added into the New_Dataset folder\".format(i))\n",
        "print(\"{0:.2%} defect\".format(d/i))\n",
        "print(\"{0:.2%} clearwood\".format(c/i))\n",
        "print(\"-----------------------------------------------------\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 images have been prepared and have been saved to Google Drive : My Drive/Project_google_colab/Classification-Bois/Images_preprocessed\n",
            "-----------------------------------------\n",
            "9 have been added into the New_Dataset\n",
            "77.78% defect\n",
            "22.22% clearwood\n",
            "-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia931eBpDoFK"
      },
      "source": [
        "**PART 3 - Warning !**\n",
        "\n",
        "The images of the dataset have been classified by the neural network wich have an overall accuracy of 94%. **To avoid mistakes in the dataset I recommand a manual check of the both folders : defect and clearwood.**"
      ]
    }
  ]
}